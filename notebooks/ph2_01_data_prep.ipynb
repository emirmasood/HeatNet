{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **YOLO Dataset Preperation**\n","\n","This notebook prepares the dataset for YOLO, which requires a specific structure and format.\n","\n","The steps are:\n","\n","- Skip unwanted classes  \n","- Read raw images and their JSON annotations  \n","- Split images into training and validation sets  \n","- Convert bounding boxes to YOLO’s normalized format  \n","- Organize images and labels into `images/` and `labels/` folders  \n","- Create the `data.yaml` configuration file  \n","- Check that every image has a matching label  \n"],"metadata":{"id":"IDkPrKzjs3Id"}},{"cell_type":"markdown","source":["## **Importing required libraries and modules**\n"],"metadata":{"id":"seXlYGwl08aG"}},{"cell_type":"code","source":["import os\n","import json\n","import shutil\n","from pathlib import Path\n","from tqdm.notebook import tqdm\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import cv2\n","import yaml"],"metadata":{"id":"_H_r4Ffj09e2","executionInfo":{"status":"ok","timestamp":1750951368308,"user_tz":-120,"elapsed":4572,"user":{"displayName":"Ismail Aljošević","userId":"17063935464990646749"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HogPGjcIAQZC","executionInfo":{"status":"ok","timestamp":1750951390378,"user_tz":-120,"elapsed":20064,"user":{"displayName":"Ismail Aljošević","userId":"17063935464990646749"}},"outputId":"fe183b53-50f4-471c-8a08-a5bd9f254c87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["base_dir = \"/content/drive/MyDrive/MLDL/6D-Pose-Estimation/data\""],"metadata":{"id":"Xbceefhd3djb","executionInfo":{"status":"ok","timestamp":1750951914707,"user_tz":-120,"elapsed":18,"user":{"displayName":"Ismail Aljošević","userId":"17063935464990646749"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### **Build zero-based class map excluding 03 and 07**\n","\n","This code snippet walks through a specified directory of class-named subfolders, skips folders `03` and `07`, and then builds a dictionary that maps each remaining folder name to a unique integer ID starting at zero."],"metadata":{"id":"UPsknnP_T3m4"}},{"cell_type":"code","source":["# Build zero-based class map excluding 03 and 07\n","source_base = \"/content/drive/MyDrive/MLDL/6D-Pose-Estimation/data/raw/data\"\n","available_folders = sorted([f for f in os.listdir(source_base) if os.path.isdir(os.path.join(source_base, f)) and f not in ['03', '07']])\n","class_map = {folder: idx for idx, folder in enumerate(available_folders)}\n","\n","print(\" Class mapping:\")\n","for f, i in class_map.items():\n","    print(f\"Class folder {f} → Class ID {i}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2WW_6I5kJr1","executionInfo":{"status":"ok","timestamp":1750880416533,"user_tz":-120,"elapsed":60,"user":{"displayName":"AAEA","userId":"14660609484008760889"}},"outputId":"1fd20c0e-8a5f-404b-ea54-4d9486f0067c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Class mapping:\n","Class folder 01 → Class ID 0\n","Class folder 02 → Class ID 1\n","Class folder 04 → Class ID 2\n","Class folder 05 → Class ID 3\n","Class folder 06 → Class ID 4\n","Class folder 08 → Class ID 5\n","Class folder 09 → Class ID 6\n","Class folder 10 → Class ID 7\n","Class folder 11 → Class ID 8\n","Class folder 12 → Class ID 9\n","Class folder 13 → Class ID 10\n","Class folder 14 → Class ID 11\n","Class folder 15 → Class ID 12\n"]}]},{"cell_type":"markdown","source":["### **Load and inspect ground-truth annotations**\n","\n","This snippet sets up your training and output directories, reads the gt.json file into a Python dictionary, and prints out a couple of its keys plus one example entry so you can quickly verify what your annotation data looks like."],"metadata":{"id":"rJO3VoK2UuvR"}},{"cell_type":"code","source":["# Define base paths\n","train_dir = os.path.join(base_dir, \"full_data/train\")\n","output_dir = os.path.join(base_dir, \"yolo_data\")  # New YOLO dataset output\n","\n","# Load gt.json\n","with open(os.path.join(train_dir, \"gt.json\")) as f:\n","    gt_data = json.load(f)\n","\n","# Inspect first 2 items\n","print(\" Sample keys from gt.json:\", list(gt_data.keys())[:2])\n","print(\" Example annotation:\", gt_data[list(gt_data.keys())[0]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rggSs47n5eAm","executionInfo":{"status":"ok","timestamp":1750880470516,"user_tz":-120,"elapsed":74,"user":{"displayName":"AAEA","userId":"14660609484008760889"}},"outputId":"0a7045df-eccc-49c7-c75f-5ecf8981eca6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample keys from gt.json: ['01_0000', '01_0001']\n","Example annotation: [[0.0963063, 0.99404401, 0.0510079, 0.57332098, -0.0135081, -0.81922001, -0.81365103, 0.10814, -0.57120699], [-105.3577515, -117.52119142, 1014.8770132], [244, 150, 44, 58]]\n"]}]},{"cell_type":"markdown","source":["# **Prepare output folders, filter and split images**\n","\n","This step sets up the YOLO output directories, picks only the images that have entries in the ground-truth JSON, then shuffles them (with a fixed seed for reproducibility) and splits them into an 80% training set and 20% validation set."],"metadata":{"id":"sFP90wPTVJmJ"}},{"cell_type":"code","source":["# Create YOLO folder structure\n","for folder in [\"images/train\", \"images/val\", \"labels/train\", \"labels/val\"]:\n","    os.makedirs(os.path.join(output_dir, folder), exist_ok=True)\n","\n","images_dir = \"/content/drive/MyDrive/MLDL/6D-Pose-Estimation/data/full_data/train/images\"\n","# Get all .png filenames\n","image_names = sorted([f for f in os.listdir(images_dir) if f.endswith(\".png\")])\n","\n","# Match only images that have corresponding bbox in gt.json (without .png)\n","available = [img for img in image_names if img.replace(\".png\", \"\") in gt_data]\n","print(f\" Found {len(available)} annotated images out of {len(image_names)}\")\n","\n","# Split into 80% train, 20% val\n","train_imgs, val_imgs = train_test_split(available, test_size=0.2, random_state=8)\n","print(f\" Train: {len(train_imgs)} images — Val: {len(val_imgs)} images\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_M2UDSH5t9C","executionInfo":{"status":"ok","timestamp":1750880519794,"user_tz":-120,"elapsed":44,"user":{"displayName":"AAEA","userId":"14660609484008760889"}},"outputId":"789e4df6-fb6e-4e8d-dc92-7c63d9b66767"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 14220 annotated images out of 14220\n","Train: 11376 images — Val: 2844 images\n"]}]},{"cell_type":"markdown","source":["## **Convert annotations to YOLO format and organize dataset**\n","\n","This code iterates over the training and validation splits. For each image, it:\n","\n","- Reads the image to obtain its size  \n","- Retrieves the corresponding bounding box and converts it to YOLO format: `<x_center> <y_center> <width> <height>`  \n","- Writes the label file for the image  \n","- Copies the image to the appropriate folder  \n","\n"],"metadata":{"id":"XvY1COfIV3We"}},{"cell_type":"code","source":["print(f\" Train: {len(train_imgs)} images — Val: {len(val_imgs)} images\")\n","\n","def convert_bbox(bbox, img_w, img_h):\n","    x, y, w, h = bbox\n","    x_center = (x + w / 2) / img_w\n","    y_center = (y + h / 2) / img_h\n","    return x_center, y_center, w / img_w, h / img_h\n","\n","# === Generate YOLO labels and copy files ===\n","for split, image_list in zip([\"train\", \"val\"], [train_imgs, val_imgs]):\n","    print(f\" Processing {split} set: {len(image_list)} images\")\n","    for name in tqdm(image_list, desc=f\" {split}\"):\n","        img_path = os.path.join(images_dir, name)\n","        dst_img_path = os.path.join(base_dir, f\"yolo_data/images/{split}/{name}\")\n","        label_path = os.path.join(base_dir, f\"yolo_data/labels/{split}/{name.replace('.png', '.txt')}\")\n","\n","        key = name.replace(\".png\", \"\")\n","        if key not in gt_data:\n","            print(f\" Missing key: {key}\")\n","            continue\n","\n","        bbox = gt_data[key][2]\n","        folder = key.split(\"_\")[0]\n","        if folder not in class_map:\n","            print(f\" Skipping {key} — unknown class {folder}\")\n","            continue\n","        class_id = class_map[folder]\n","\n","\n","        # Validate image\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            print(f\" Unreadable image: {img_path}\")\n","            continue\n","        h, w = img.shape[:2]\n","\n","        # Convert and write label\n","        x_center, y_center, norm_w, norm_h = convert_bbox(bbox, w, h)\n","        with open(label_path, \"w\") as f:\n","            f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {norm_w:.6f} {norm_h:.6f}\\n\")\n","\n","        # Copy image\n","        shutil.copyfile(img_path, dst_img_path)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"32UgMt-m6NHK","executionInfo":{"status":"ok","timestamp":1750880571860,"user_tz":-120,"elapsed":66,"user":{"displayName":"AAEA","userId":"14660609484008760889"}},"outputId":"59758b6f-e980-4e5a-edea-6a54480fa191"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train: 11376 images — Val: 2844 images\n","Processing train set: 11376 images\n","\n"," train: 100%|██████████| 11376/11376 [05:44<00:00, 33.02it/s]\n","\n","Processing val set: 2844 images\n","\n","val: 100%|██████████| 2844/2844 [01:24<00:00, 33.59it/s]\n","\n"]}]},{"cell_type":"markdown","source":["# **Create YOLO data.yaml configuration**\n","This step creates a `data.yaml` file required by YOLO, which contains:\n","\n","- The directory path for training images  \n","- The directory path for validation images  \n","- The total number of classes (13)  \n","- The ordered list of class names  \n","\n","This file tells YOLO where to find the data and how to correctly assign labels to each object.\n"],"metadata":{"id":"Rd--m4ZpWFaX"}},{"cell_type":"code","source":["data_yaml = {\n","    \"train\": \"/content/drive/MyDrive/MLDL/6D-Pose-Estimation/data/yolo_data/images/train\",\n","    \"val\": \"/content/drive/MyDrive/MLDL/6D-Pose-Estimation/data/yolo_data/images/val\",\n","    \"nc\": 13,\n","    \"names\": [\n","        \"ape\", \"benchvise\", \"camera\", \"can\", \"cat\", \"driller\", \"duck\",\n","        \"eggbox\", \"glue\", \"holepuncher\", \"iron\", \"lamp\", \"phone\"\n","    ]\n","}\n","\n","yaml_path = \"/content/drive/MyDrive/MLDL/6D-Pose-Estimation/data/yolo_data/data.yaml\"\n","\n","with open(yaml_path, \"w\") as f:\n","    yaml.dump(data_yaml, f)\n","\n","print(f\" data.yaml created at {yaml_path}\")\n","\n"],"metadata":{"id":"eT-Y5DF79YcD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750880633401,"user_tz":-120,"elapsed":31,"user":{"displayName":"AAEA","userId":"14660609484008760889"}},"outputId":"3dfcfba8-70df-44a1-807c-47071b345da1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data.yaml created at /content/drive/MyDrive/MLDL/6D-Pose-Estimation/data/yolo_data/data.yam\n"]}]},{"cell_type":"markdown","source":["# **Validate image–label correspondence for each split**\n","This code checks both the training and validation folders to ensure every .png image has a matching .txt label file and vice versa, reporting the total counts and listing any mismatches."],"metadata":{"id":"Du2dn_8XWLqH"}},{"cell_type":"code","source":["image_dir = \"/content/drive/MyDrive/MLDL/6D-Pose-Estimation/data/yolo_data/images\"\n","label_dir = \"/content/drive/MyDrive/MLDL/6D-Pose-Estimation/data/yolo_data/labels\"\n","\n","def validate_split(split):\n","    print(f\"\\n Checking {split.upper()} split:\")\n","    img_path = os.path.join(image_dir, split)\n","    lbl_path = os.path.join(label_dir, split)\n","\n","    image_files = sorted([f[:-4] for f in os.listdir(img_path) if f.endswith(\".png\")])\n","    label_files = sorted([f[:-4] for f in os.listdir(lbl_path) if f.endswith(\".txt\")])\n","\n","    missing_labels = sorted(set(image_files) - set(label_files))\n","    missing_images = sorted(set(label_files) - set(image_files))\n","\n","    print(f\" Total images: {len(image_files)}\")\n","    print(f\" Total labels: {len(label_files)}\")\n","\n","    if missing_labels:\n","        print(f\" {len(missing_labels)} image(s) missing labels:\")\n","        print(missing_labels[:5], \"...\" if len(missing_labels) > 5 else \"\")\n","    else:\n","        print(\" All images have labels.\")\n","\n","    if missing_images:\n","        print(f\" {len(missing_images)} label(s) missing images:\")\n","        print(missing_images[:5], \"...\" if len(missing_images) > 5 else \"\")\n","    else:\n","        print(\" All labels have images.\")\n","\n","# Run for both splits\n","validate_split(\"train\")\n","validate_split(\"val\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UorvxNLQrAcS","executionInfo":{"status":"ok","timestamp":1750880705669,"user_tz":-120,"elapsed":46,"user":{"displayName":"AAEA","userId":"14660609484008760889"}},"outputId":"e08803de-d746-47c7-f73f-a470364887a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Checking TRAIN split:\n"," Total images: 11376\n"," Total labels: 11376\n"," All images have labels.\n"," All labels have images.\n","\n"," Checking VAL split:\n"," Total images: 2844\n"," Total labels: 2844\n"," All images have labels.\n"," All labels have images.\n"]}]}]}
