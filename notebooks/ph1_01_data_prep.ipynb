{"cells":[{"cell_type":"markdown","source":["# **General Data Preparation**\n","\n","In this notebook, we perform general data preparation steps required for the project. These include:\n","\n","- Moving all necessary files to the appropriate directories  \n","- Defining the naming conventions for the dataset  \n","- Splitting the data into training and testing subsets  \n","\n","These steps ensure the data is properly organized and ready for further processing and model development.\n"],"metadata":{"id":"J-zF7ibKibEv"}},{"cell_type":"markdown","metadata":{"id":"5PnZJnu9f-w_"},"source":["# Splitting data into training and test set\n","- The data will be split into training and test sets. The training set will consist of 90% of the data, while the test set will consist of the remaining 10%. The object classes will be distributed uniformly across both sets.\n","\n","- Defined path: full_data/train, full_data/test"]},{"cell_type":"markdown","source":["## **Importing required libraries and modules**"],"metadata":{"id":"Na1GSItBjHqv"}},{"cell_type":"code","source":["%pip install ruamel.yaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TgMnPjEkstXf","executionInfo":{"status":"ok","timestamp":1750949102242,"user_tz":-120,"elapsed":10210,"user":{"displayName":"Ismail Aljošević","userId":"17063935464990646749"}},"outputId":"8455806c-b081-4ba6-a1db-a9aa53ded548"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ruamel.yaml\n","  Downloading ruamel.yaml-0.18.14-py3-none-any.whl.metadata (24 kB)\n","Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml)\n","  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n","Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml\n","Successfully installed ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AueGfNxJfljT"},"outputs":[],"source":["import numpy as np\n","import os\n","import shutil\n","import yaml\n","import json\n","from sklearn.model_selection import train_test_split\n","from ruamel.yaml import YAML"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14875,"status":"ok","timestamp":1750949157960,"user":{"displayName":"Ismail Aljošević","userId":"17063935464990646749"},"user_tz":-120},"id":"pWJsFv2TqYoq","outputId":"7d5aae0e-f6e9-47c8-88f7-487827478b5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PK7HZ29eg1gd"},"outputs":[],"source":["PROJECT_BASE = \"/content/drive/MyDrive/MLDL/6D-Pose-Estimation\""]},{"cell_type":"markdown","source":["# **Loading and Aggregating Image Filenames from Structured Subdirectories**\n","\n","The `load_images` function creates a list of image filenames from selected folders. It defines valid folder names from \"01\" to \"15\", but skips \"03\" and \"07\".\n","\n","For each valid folder, it builds the full path by combining `source_path`, the folder name, and `dest_fold`. Then, it lists and sorts all filenames inside that folder and adds them to the `image_labels` list.\n","\n","The function returns a list where each element contains the sorted filenames from one folder. This list is ready for further image processing or labeling tasks.\n","\n","The same procedure is performed for both **depth** and **RGB** images."],"metadata":{"id":"6CFgbYNhX-m8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bopUgzCBgtqV"},"outputs":[],"source":["def load_images(source_path, dest_fold):\n","\n","  valid_folders = [f\"{i:02d}\" for i in range(1, 16) if f\"{i:02d}\" not in [\"03\", \"07\"]]\n","\n","  image_labels = []\n","\n","  for folder in valid_folders:\n","\n","    images_path = os.path.join(source_path, folder, dest_fold)\n","    image_labels.append(sorted(os.listdir(images_path)))\n","\n","  return image_labels\n"]},{"cell_type":"markdown","source":["### **RGB**"],"metadata":{"id":"wGAWIHgWj1qc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HRSilWoUha8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750949252070,"user_tz":-120,"elapsed":106,"user":{"displayName":"Ismail Aljošević","userId":"17063935464990646749"}},"outputId":"9ff7a490-0aa6-4c9c-d1a3-5ecd7f4226b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["source_path = os.path.join(PROJECT_BASE, \"data/raw/data\")\n","image_labels = load_images(source_path, \"rgb\")"]},{"cell_type":"markdown","metadata":{"id":"rOJuxEqe6B59"},"source":["### **Depth**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZY4sm3q6Dd8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750949265931,"user_tz":-120,"elapsed":21,"user":{"displayName":"Ismail Aljošević","userId":"17063935464990646749"}},"outputId":"5d3a5f9c-b2d0-440b-f9c4-77699550e154"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["source_path = os.path.join(PROJECT_BASE, \"data/raw/data\")\n","image_depth_labels = load_images(source_path, \"depth\")"]},{"cell_type":"markdown","metadata":{"id":"0NqERw0Siyeh"},"source":["### The naming convention for images is: *classId_image_number*\n"]},{"cell_type":"markdown","source":["## **Consolidate and relabel all images**\n","\n","This step takes every image from its original class-specific folder, copies them into a single directory, and renames each file by prefixing it with its class ID. The result is a unified dataset where each filename carries its class label, making downstream processing and organization much simpler."],"metadata":{"id":"wdUQvHhoYDYv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RvFK1SN1iY6D"},"outputs":[],"source":["def move_all_images(image_labels, destination_path):\n","\n","  images_base_path = os.path.join(PROJECT_BASE, \"data/raw/data\")\n","  valid_folders = [f\"{i:02d}\" for i in range(1, 16) if f\"{i:02d}\" not in [\"03\", \"07\"]]\n","  class_map = {idx: cls  for idx, cls in enumerate(valid_folders)}\n","\n","  for i, image_group in enumerate(image_labels):\n","    for label in image_group:\n","      image_path = os.path.join(images_base_path, class_map[i], \"rgb\", label)\n","      dst_path = os.path.join(destination_path, f\"{class_map[i]}_{label}\")\n","      shutil.copy2(image_path, dst_path)"]},{"cell_type":"markdown","source":["### **RGB**"],"metadata":{"id":"UfwZvE4YkaAl"}},{"cell_type":"code","source":["destination_path_rgb = os.path.join(PROJECT_BASE, \"data/full_data/images\")\n","move_all_images(image_labels, destination_path_rgb)"],"metadata":{"id":"YnBzFnIzkcVK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Depth**"],"metadata":{"id":"03q1823CkqoU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"H7d2LAmPlcP1","collapsed":true},"outputs":[],"source":["destination_path_depth = os.path.join(PROJECT_BASE, \"data/full_data/depth\")\n","move_all_images(image_depth_labels, destination_path_depth)"]},{"cell_type":"markdown","source":["## **Split Images into Training and Test Sets**\n","\n","This step assigns a class label to each image based on its folder name. It then uses `train_test_split` from scikit-learn to randomly divide the images into 90% for training and 10% for testing, while keeping the same class proportions in both sets.\n","\n","The same procedure is performed for both **depth** and **RGB** images.\n","\n"],"metadata":{"id":"0FP8SSPMYTYu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDEXQ3wFpDjZ"},"outputs":[],"source":["def split_into_train_test(input_path, input_files):\n","\n","  valid_folders = [f\"{i:02d}\" for i in range(1, 16) if f\"{i:02d}\" not in [\"03\", \"07\"]]\n","  class_map = {idx: cls  for idx, cls in enumerate(valid_folders)}\n","  labels = [class_map[i] for i, img_group in enumerate(image_labels) for _ in img_group]\n","\n","  X_train, X_test, y_train, y_test = train_test_split(\n","    all_images, labels, test_size=0.1, random_state=42, stratify=labels\n","  )\n","\n","  return X_train, X_test"]},{"cell_type":"markdown","source":["### **RGB**"],"metadata":{"id":"hPJ01OZ-mfWM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXVpQavX6cMK"},"outputs":[],"source":["all_images = sorted(os.listdir(destination_path_rgb))\n","train_images, test_images = split_into_train_test(destination_path_rgb, all_images)"]},{"cell_type":"markdown","source":["### **Depth**"],"metadata":{"id":"z3UaY7Egmg89"}},{"cell_type":"code","source":["all_depth_images = sorted(os.listdir(destination_path_depth))\n","train_depth_images, test_depth_images = split_into_train_test(destination_path_depth, all_depth_images)"],"metadata":{"id":"_4d-xePXmjWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1750949393119,"user":{"displayName":"Ismail Aljošević","userId":"17063935464990646749"},"user_tz":-120},"id":"o1eJ5AsB8xHW","outputId":"5295f92c-6208-4ce4-991f-0dde1db14c3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["(14220, 1580)\n"]}],"source":["len(train_images), len(test_images)"]},{"cell_type":"markdown","metadata":{"id":"icbNN5bmsG-x"},"source":["## **Moving Test Images to a Separate Folder**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEa3_PynsZuQ"},"outputs":[],"source":["def move_test_images(X_test, source_root, dest_root):\n","\n","    os.makedirs(dest_root, exist_ok=True)\n","\n","    for img_name in X_test:\n","        src_path = os.path.join(source_root, img_name)\n","        dst_path = os.path.join(dest_root, img_name)\n","\n","        if os.path.exists(src_path):\n","            shutil.move(src_path, dst_path)\n","        else:\n","            print(f\"Warning: {src_path} does not exist!\")\n"]},{"cell_type":"markdown","source":["### **RGB**"],"metadata":{"id":"orsDrjCpl51v"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ic4o0r3m9h5V"},"outputs":[],"source":["input_path = os.path.join(PROJECT_BASE, \"data/full_data/images\")\n","dest_path = os.path.join(PROJECT_BASE, \"data/full_data/test/images\")\n","\n","move_test_images(test_images, input_path, dest_path)"]},{"cell_type":"markdown","source":["### **Depth**"],"metadata":{"id":"M2htzKVOl9cs"}},{"cell_type":"code","source":["input_path = os.path.join(PROJECT_BASE, \"data/full_data/depth\")\n","dest_path = os.path.join(PROJECT_BASE, \"data/full_data/test/depth\")\n","\n","move_test_images(test_depth_images, input_path, dest_path)"],"metadata":{"id":"-AV57jQQl8V_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- After moving the test images, all remaining images in the `full_data/images` folder are considered part of the training set.\n"],"metadata":{"id":"F6IAmVaknIlF"}},{"cell_type":"markdown","source":["# **Generating the Appropriate Ground Truth Data**\n","\n","In this step, we create a unified `gt.json` file that contains ground truth data from all class-specific `.yml` files, combined into a single structure.\n","\n","After that, we perform the same procedure as with the images — we separate `gt.json` files for the training set and for the test set.\n"],"metadata":{"id":"asfdxKS-njk_"}},{"cell_type":"markdown","source":["### **Formatting the YML File for Class 02**\n","\n","The YML file for class `02` had a slightly different structure compared to the others. It contained ground truth data for all objects present in the image, not just for class `02`, as is the case with the other class-specific files.\n","\n","In this step, we extract only the relevant ground truth information for class `02` to make the structure consistent with the rest of the dataset.\n"],"metadata":{"id":"GD9dwS1SphSI"}},{"cell_type":"code","source":["yaml_loader = YAML()\n","yaml_loader.width = 1000\n","yaml_loader.indent(mapping=2, sequence=4, offset=2)\n","yaml_loader.default_flow_style = False\n","\n","def force_flow_style_lists(obj):\n","  if isinstance(obj, list):\n","      seq = yaml_loader.seq(obj)\n","      seq.fa.set_flow_style()\n","      return seq\n","  elif isinstance(obj, dict):\n","      return {k: force_flow_style_lists(v) for k, v in obj.items()}\n","  else:\n","      return obj\n","\n","def format_yml_file(input_path, output_path, object_id):\n","\n","  with open(input_path, \"r\") as f:\n","      data = yaml_loader.load(f)\n","\n","  filtered = {}\n","  for frame, objects in data.items():\n","      result = []\n","      for obj in objects:\n","          if obj.get(\"obj_id\") == object_id:\n","              result.append(force_flow_style_lists(obj))\n","      if result:\n","          filtered[int(frame)] = result\n","\n","  with open(output_path, \"w\") as f:\n","      yaml_loader.dump(filtered, f)\n"],"metadata":{"id":"0Lu1wUZGpwkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_base_path = os.path.join(PROJECT_BASE, \"data/raw/data\")\n","yml_input_path = os.path.join(labels_base_path, \"02\", \"gt.yml\")\n","yml_output_path = os.path.join(labels_base_path, \"02\", \"gt_new.yml\") #later we renamed to the gt.yml\n","format_yml_file(yml_input_path, yml_output_path, 2)"],"metadata":{"id":"qoPzAVKwqB9Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Loading Ground Truth (.yml) Files for All Classes**\n"],"metadata":{"id":"QZd3IRszqV5R"}},{"cell_type":"code","source":["def read_yml_file(path):\n","  with open(path, 'r') as file:\n","    data = yaml.safe_load(file)\n","  return data"],"metadata":{"id":"a1VPWHaTscnw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels_base_path = os.path.join(PROJECT_BASE, \"data/raw/data\")\n","valid_folders = [f\"{i:02d}\" for i in range(1, 16) if f\"{i:02d}\" not in [\"03\", \"07\"]]\n","\n","yml_files = []\n","\n","for folder in valid_folders:\n","\n","  yml_path = os.path.join(labels_base_path, folder, \"gt.yml\")\n","  yml_files.append(read_yml_file(yml_path))"],"metadata":{"id":"ZPTdaxJEq8O3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Merging All YML Files into a Single JSON File**"],"metadata":{"id":"TuyjfwjEvO6T"}},{"cell_type":"code","source":["def make_integrated_json_file(yml_files, class_map, json_output_path):\n","\n","  gt_rot_trans_bb_data = {}\n","\n","  for i, yml in enumerate(yml_files):\n","\n","    for key, value in yml.items():\n","\n","      rotation = value[0]['cam_R_m2c']\n","      translation = value[0]['cam_t_m2c']\n","      border_box = value[0]['obj_bb']\n","\n","      gt_rot_trans_bb_data[f\"{class_map[i]}_{key:04d}\"] = [rotation, translation, border_box]\n","\n","  # Exporting JSON file\n","  with open(json_output_path, 'w') as f:\n","    json.dump(gt_rot_trans_bb_data, f, indent=2)\n","\n","  return gt_rot_trans_bb_data"],"metadata":{"id":"Sz6nCusYpWGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_output_path = os.path.join(PROJECT_BASE, \"data\", \"full_data\", \"gt.json\")\n","class_map = {idx: cls  for idx, cls in enumerate(valid_folders)}\n","gt_rot_trans_bb_data = make_integrated_json_file(yml_files, class_map, json_output_path)"],"metadata":{"id":"2TDX2Riwqt7X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Splitting integrated json for training and test**"],"metadata":{"id":"y2dcf9xBwdNZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJ-DElM9tAfG"},"outputs":[],"source":["def split_json(json_path, train_images, test_images, output_path_train, output_path_test):\n","\n","  #Load json\n","  with open(json_path, \"r\") as f:\n","    data = json.load(f)\n","  train_json = {key:value for key, value in data.items() if f\"{key}.png\" in train_images}\n","  test_json = {key:value for key, value in data.items() if f\"{key}.png\" in test_images}\n","\n","    # Export JSONs\n","  with open(output_path_train, \"w\") as f:\n","      json.dump(train_json, f, indent=4)\n","\n","  with open(output_path_test, \"w\") as f:\n","      json.dump(test_json, f, indent=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9suQhHR_4r7"},"outputs":[],"source":["train_images = os.listdir(os.path.join(PROJECT_BASE, \"data/full_data/train/images\"))\n","test_images = os.listdir(os.path.join(PROJECT_BASE, \"data/full_data/test/images\"))\n","\n","output_train_json = os.path.join(PROJECT_BASE, \"data/full_data/train/gt.json\")\n","output_test_json = os.path.join(PROJECT_BASE, \"data/full_data/test/gt.json\")\n","\n","split_json(json_output_path, train_images, test_images, output_train_json, output_test_json)"]},{"cell_type":"markdown","source":["# **All further experiments and additional data preparation in other notebooks will be performed only on the training set.**\n"],"metadata":{"id":"WecU-o2uzXUd"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}